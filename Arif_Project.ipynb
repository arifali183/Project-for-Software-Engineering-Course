{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Failure Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title : Machine Learning based Heart Failure Prediction using Principle Component Analysis and Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members: Arif Ali and Mujahid Khan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know more about the problem, data and the solutions, readers can refer to the following research papers that recenlty got published.\n",
    "\n",
    "Paper No 1: L. Ali and S. Bukhari, “An approach based on mutually informed neural networks to optimize the generalization capabilities of decision support systems developed for heart failure prediction,” IRBM, 2020. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S1959031820300828\n",
    "\n",
    "Paper No 2: L. Ali, A. Niamat, J. A. Khan, N. A. Golilarz, X. Xingzhong, A. Noor, R. Nour, and S. A. C. Bukhari, “An optimized stacked support vector machines based expert system for the effective prediction of heart failure,” IEEE Access, vol. 7, pp. 54 007–54 014, 2019.\n",
    "\n",
    "Paper No 3: L. Ali, A. Rahman, A. Khan, M. Zhou, A. Javeed, and J. A. Khan, “An automated diagnostic system for heart disease prediction based on Chi2 statistical model and optimally configured deep neural network,” IEEE Access, vol. 7, pp. 34 938–34 945, 2019.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement:  Heart is a vital organ of human body and is responsible for pumping blood to other organs of the body. Heart failure (HF) is a serious disorder with high prevalence. HF is prevalent in developed countries at a rate of approximately 2% in the adult population and about 8% in older subjects. Moreover, literature shows that about 3-5% of hospitals admissions have connection with HF incidents. Moreover, HF diagnosis is very costly owing to the fact that in developed countries HF accounts for 2\\% of the total health costs. Hence, development of non-invasive methods for HF detection based on machine learning and data mining will help improve quality of life and reduce the associated medical costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "global Best_Acc\n",
    "Best_Acc=0\n",
    "import time\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "df = pd.read_csv(\"D:\\/Processed_Clevland_Dataset_FromNet.txt\")\n",
    "\n",
    "#I Checked it. It is correct dataset\n",
    "X = numpy.array(df)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 14)\n",
      "Feature Vector Size= (297, 13)\n",
      "[0 2 1 0 0 0 3 0 2 1 0 0 2 0 0 0 1 0 0 0 0 0 1 3 4 0 0 0 0 3 0 2 1 0 0 0 3\n",
      " 1 3 0 4 0 0 0 1 4 0 4 0 0 0 0 2 0 1 1 1 1 0 0 2 0 1 0 2 2 1 0 2 1 0 3 1 1\n",
      " 1 0 1 0 0 3 0 0 0 3 0 0 0 0 0 0 3 0 0 0 1 2 3 0 0 0 0 0 0 3 0 2 1 2 3 1 1\n",
      " 0 2 2 0 0 0 3 2 3 4 0 3 1 0 3 3 0 0 0 0 0 0 0 0 4 3 1 0 0 1 0 1 0 1 4 0 0\n",
      " 0 0 0 0 4 3 1 1 1 2 0 0 4 0 0 0 0 0 1 0 3 0 1 0 4 1 0 1 0 0 3 2 0 0 1 0 0\n",
      " 2 1 2 0 3 2 0 3 0 0 0 1 0 0 0 0 0 3 3 3 0 1 0 4 0 3 1 0 0 0 0 0 0 0 0 3 1\n",
      " 0 0 0 3 2 0 2 1 0 0 3 2 1 0 0 0 0 0 2 0 2 2 1 3 0 0 1 0 0 0 0 0 0 0 1 0 3\n",
      " 0 0 4 2 2 1 0 1 0 2 0 1 0 0 0 1 0 2 0 3 0 2 4 2 0 0 1 0 2 2 1 0 3 1 1 2 3\n",
      " 1]\n",
      "Index(['age', 'sex', 'chestpain', 'BP', 'SerumCholestrol', 'FBS',\n",
      "       'RestingElectrocardiography', 'HeartRate', 'EIAngina', 'OldPeak',\n",
      "       'SlopofST', 'flouroscorpy', 'thal', 'label'],\n",
      "      dtype='object')\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "df_new = df.drop([87, 166, 192, 266, 287, 302], 0)\n",
    "print(df_new.shape)\n",
    "\n",
    "df_X= df_new.drop('label',1)\n",
    "Y_df = df_new.iloc[:,13]\n",
    "df_numpy = numpy.array(df_new)\n",
    "\n",
    "X = numpy.delete(df_numpy, 13, 1)\n",
    "print(\"Feature Vector Size=\", X.shape)\n",
    "Y = numpy.array(Y_df)\n",
    "print(Y)\n",
    "print(df.columns)\n",
    "print(Y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i<=296:\n",
    "    if Y[i]!=0:\n",
    "        Y[i]=1\n",
    "        #print(i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_GNB(X_FS, Y):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_FS, Y, test_size=0.3, random_state=42)\n",
    "    global Best_Acc\n",
    "    Best_Sen = 0\n",
    "    Best_Spec = 0\n",
    "    \n",
    "    TP = 0 \n",
    "    TP_train=0\n",
    "    FN=0   \n",
    "    FN_train=0\n",
    "    FP=0   \n",
    "    FP_train=0\n",
    "    TN = 0 \n",
    "    TN_train=0\n",
    "    model =  GaussianNB()\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Acc = accuracy_score(Y_test, Y_pred)*100\n",
    "\n",
    "    ########For Sensitvity and specificity#########\n",
    "    k=0\n",
    "    while k<len(Y_pred):\n",
    "        if Y_test[k]==Y_pred[k]==1:\n",
    "            TP = TP+1\n",
    "        if Y_test[k]==Y_pred[k]==0:\n",
    "            TN = TN+1\n",
    "        k=k+1\n",
    "    FN = 41-TP\n",
    "    FP = 49-TN\n",
    "    Sensitivity = (TP/(TP+FN))*100\n",
    "    Specificity = (TN/(TN+FP))*100\n",
    "    if Acc>=Best_Acc:\n",
    "        Best_Acc = Acc\n",
    "        print(\"Best Test Acc ===========================================================\", Acc)\n",
    "        print(\"X_FS Size=\", X_train.shape)\n",
    "        print(\"Sensitivity =\", Sensitivity)\n",
    "        print(\"Specificity =, \", Specificity)\n",
    "        print(\"MCC =====\", matthews_corrcoef(Y_test, Y_pred))\n",
    "        Y_pred = model.predict(X_train)\n",
    "        Acc_train = accuracy_score(Y_train, Y_pred)*100\n",
    "        print(\"Train Accuracy ===============================================\", Acc_train)\n",
    "\n",
    "        print(\"TP = \", TP)\n",
    "        print(\"TN = \", TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Feature Vector Size  = (297, 1)\n",
      "Best Test Acc =========================================================== 53.333333333333336\n",
      "X_FS Size= (207, 1)\n",
      "Sensitivity = 26.82926829268293\n",
      "Specificity =,  75.51020408163265\n",
      "MCC ===== 0.026712010096692274\n",
      "Train Accuracy =============================================== 59.90338164251207\n",
      "TP =  11\n",
      "TN =  37\n",
      "New Feature Vector Size  = (297, 2)\n",
      "Best Test Acc =========================================================== 73.33333333333333\n",
      "X_FS Size= (207, 2)\n",
      "Sensitivity = 56.09756097560976\n",
      "Specificity =,  87.75510204081633\n",
      "MCC ===== 0.46732823779423044\n",
      "Train Accuracy =============================================== 68.59903381642512\n",
      "TP =  23\n",
      "TN =  43\n",
      "New Feature Vector Size  = (297, 3)\n",
      "Best Test Acc =========================================================== 75.55555555555556\n",
      "X_FS Size= (207, 3)\n",
      "Sensitivity = 60.97560975609756\n",
      "Specificity =,  87.75510204081633\n",
      "MCC ===== 0.5107235342397549\n",
      "Train Accuracy =============================================== 67.14975845410628\n",
      "TP =  25\n",
      "TN =  43\n",
      "New Feature Vector Size  = (297, 4)\n",
      "New Feature Vector Size  = (297, 5)\n",
      "Best Test Acc =========================================================== 83.33333333333334\n",
      "X_FS Size= (207, 5)\n",
      "Sensitivity = 80.48780487804879\n",
      "Specificity =,  85.71428571428571\n",
      "MCC ===== 0.6635087809810993\n",
      "Train Accuracy =============================================== 77.29468599033817\n",
      "TP =  33\n",
      "TN =  42\n",
      "New Feature Vector Size  = (297, 6)\n",
      "Best Test Acc =========================================================== 85.55555555555556\n",
      "X_FS Size= (207, 6)\n",
      "Sensitivity = 85.36585365853658\n",
      "Specificity =,  85.71428571428571\n",
      "MCC ===== 0.7095662904602299\n",
      "Train Accuracy =============================================== 77.29468599033817\n",
      "TP =  35\n",
      "TN =  42\n",
      "New Feature Vector Size  = (297, 7)\n",
      "Best Test Acc =========================================================== 85.55555555555556\n",
      "X_FS Size= (207, 7)\n",
      "Sensitivity = 85.36585365853658\n",
      "Specificity =,  85.71428571428571\n",
      "MCC ===== 0.7095662904602299\n",
      "Train Accuracy =============================================== 78.26086956521739\n",
      "TP =  35\n",
      "TN =  42\n",
      "New Feature Vector Size  = (297, 8)\n",
      "Best Test Acc =========================================================== 87.77777777777777\n",
      "X_FS Size= (207, 8)\n",
      "Sensitivity = 85.36585365853658\n",
      "Specificity =,  89.79591836734694\n",
      "MCC ===== 0.7533069618657593\n",
      "Train Accuracy =============================================== 79.71014492753623\n",
      "TP =  35\n",
      "TN =  44\n",
      "New Feature Vector Size  = (297, 9)\n",
      "Best Test Acc =========================================================== 87.77777777777777\n",
      "X_FS Size= (207, 9)\n",
      "Sensitivity = 82.92682926829268\n",
      "Specificity =,  91.83673469387756\n",
      "MCC ===== 0.7538526991797708\n",
      "Train Accuracy =============================================== 81.64251207729468\n",
      "TP =  34\n",
      "TN =  45\n",
      "New Feature Vector Size  = (297, 10)\n",
      "Best Test Acc =========================================================== 87.77777777777777\n",
      "X_FS Size= (207, 10)\n",
      "Sensitivity = 82.92682926829268\n",
      "Specificity =,  91.83673469387756\n",
      "MCC ===== 0.7538526991797708\n",
      "Train Accuracy =============================================== 80.67632850241546\n",
      "TP =  34\n",
      "TN =  45\n",
      "New Feature Vector Size  = (297, 11)\n",
      "Best Test Acc =========================================================== 88.88888888888889\n",
      "X_FS Size= (207, 11)\n",
      "Sensitivity = 82.92682926829268\n",
      "Specificity =,  93.87755102040816\n",
      "MCC ===== 0.7773867978556046\n",
      "Train Accuracy =============================================== 82.1256038647343\n",
      "TP =  34\n",
      "TN =  46\n",
      "New Feature Vector Size  = (297, 12)\n",
      "Best Test Acc =========================================================== 88.88888888888889\n",
      "X_FS Size= (207, 12)\n",
      "Sensitivity = 82.92682926829268\n",
      "Specificity =,  93.87755102040816\n",
      "MCC ===== 0.7773867978556046\n",
      "Train Accuracy =============================================== 83.09178743961353\n",
      "TP =  34\n",
      "TN =  46\n",
      "New Feature Vector Size  = (297, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "Best_Acc=0\n",
    "N = range(1, 14)\n",
    "for n in N:\n",
    "    pca = PCA(n_components=n, svd_solver='full')\n",
    "    X_new = pca.fit_transform(X, Y)\n",
    "    print(\"New Feature Vector Size  =\", X_new.shape)\n",
    "    #evaluation_RBFSVM(X_FS, Y)\n",
    "    evaluation_GNB(X_new, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model with optimal components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Feature Vector Size  = (297, 13)\n",
      "Best Testing Acc =========================================================== 88.88888888888889\n",
      "X_FS Size= (207, 12)\n",
      "Sensitivity = 82.92682926829268\n",
      "Specificity =,  93.87755102040816\n",
      "MCC ===== 0.7773867978556046\n",
      "Train Accuracy =============================================== 83.09178743961353\n",
      "TP =  34\n",
      "TN =  46\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=12, svd_solver='full')\n",
    "X_FS = pca.fit_transform(X, Y)\n",
    "print(\"New Feature Vector Size  =\", X_new.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_FS, Y, test_size=0.3, random_state=42)\n",
    "global Best_Acc\n",
    "Best_Sen = 0\n",
    "Best_Spec = 0\n",
    "\n",
    "TP = 0 \n",
    "TP_train=0\n",
    "FN=0   \n",
    "FN_train=0\n",
    "FP=0   \n",
    "FP_train=0\n",
    "TN = 0 \n",
    "TN_train=0\n",
    "model =  GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "Acc = accuracy_score(Y_test, Y_pred)*100\n",
    "\n",
    "########For Sensitvity and specificity#########\n",
    "k=0\n",
    "while k<len(Y_pred):\n",
    "    if Y_test[k]==Y_pred[k]==1:\n",
    "        TP = TP+1\n",
    "    if Y_test[k]==Y_pred[k]==0:\n",
    "        TN = TN+1\n",
    "    k=k+1\n",
    "FN = 41-TP\n",
    "FP = 49-TN\n",
    "Sensitivity = (TP/(TP+FN))*100\n",
    "Specificity = (TN/(TN+FP))*100\n",
    "if Acc>=Best_Acc:\n",
    "    Best_Acc = Acc\n",
    "    print(\"Best Testing Acc ===========================================================\", Acc)\n",
    "    print(\"X_FS Size=\", X_train.shape)\n",
    "    print(\"Sensitivity =\", Sensitivity)\n",
    "    print(\"Specificity =, \", Specificity)\n",
    "    print(\"MCC =====\", matthews_corrcoef(Y_test, Y_pred))\n",
    "    Y_pred = model.predict(X_train)\n",
    "    Acc_train = accuracy_score(Y_train, Y_pred)*100\n",
    "    print(\"Train Accuracy ===============================================\", Acc_train)\n",
    "\n",
    "    print(\"TP = \", TP)\n",
    "    print(\"TN = \", TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
